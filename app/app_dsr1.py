import streamlit as st
import time
import torch
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain.prompts import PromptTemplate
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from bert_score import score as bert_score

# ----------------------------
# é¡µé¢è®¾ç½®
# ----------------------------
st.set_page_config(page_title="ğŸ§  RAG åŒ»ç–—é—®ç­”ç³»ç»Ÿ", layout="wide")
st.title("ğŸ§¬ æœ¬åœ°éƒ¨ç½²çš„å¤šæ¨¡å‹RAGåŒ»ç–—é—®ç­”ç³»ç»Ÿ")

# ----------------------------
# æ¨¡å‹é€‰æ‹©å™¨
# ----------------------------
model_options = ["deepseek-r1:8b", "qwen3:8b", "llama3.1:8b", "gemma3:latest"]
selected_model = st.selectbox("ğŸ§  é€‰æ‹©æœ¬åœ°å¤§æ¨¡å‹ï¼š", model_options, index=0)
## è¯·æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„
vect_path = "D:\\Python_projects\\LLM\\MEDgpt-RAG\\data\\vect_medical_knowledge"

# ----------------------------
# åŠ è½½å‘é‡æ•°æ®åº“
# ----------------------------
@st.cache_resource
def load_vectorstore():
    embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")
    return FAISS.load_local(vect_path, embedding_model, allow_dangerous_deserialization=True)

vectorstore = load_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})  # å¬å› 10 æ¡æ–‡æ¡£

# ----------------------------
# åŠ è½½ Reranker æ¨¡å‹
# ----------------------------
@st.cache_resource
def load_reranker():
    tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-reranker-base")
    model = AutoModelForSequenceClassification.from_pretrained("BAAI/bge-reranker-base")
    return tokenizer, model

tokenizer, reranker_model = load_reranker()

def rerank(query, docs, top_k=5):
    pairs = [(query, doc.page_content) for doc in docs]
    inputs = tokenizer.batch_encode_plus(pairs, padding=True, truncation=True, return_tensors="pt", max_length=512)
    with torch.no_grad():
        scores = reranker_model(**inputs).logits.squeeze()
    ranked_docs = [doc for _, doc in sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)]
    return ranked_docs[:top_k]

# ----------------------------
# Prompt æ¨¡æ¿
# ----------------------------
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ä½ æ˜¯ä¸€ä½åŒ»å­¦çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å†…å®¹å›ç­”é—®é¢˜ï¼Œä¸è¦åŠ å…¥ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·å›ç­”â€œæˆ‘æ— æ³•ç¡®å®šç­”æ¡ˆâ€ã€‚

ã€ä¸Šä¸‹æ–‡ã€‘
{context}

ã€é—®é¢˜ã€‘
{question}

ã€å›ç­”ã€‘
""".strip()
)

# ----------------------------
# LLM åˆå§‹åŒ–
# ----------------------------
llm = ChatOllama(model=selected_model, temperature=0.7, stream=True)

# ----------------------------
# ç”¨æˆ·è¾“å…¥
# ----------------------------
query = st.text_input("ğŸ’¬ è¯·è¾“å…¥ä½ çš„åŒ»å­¦é—®é¢˜ï¼š", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯é«˜è¡€å‹çš„å¸¸è§å¹¶å‘ç—‡ï¼Ÿ")
reference_answer = st.text_area("ğŸ¯ å¯é€‰ï¼šè¾“å…¥å‚è€ƒç­”æ¡ˆä»¥è¯„ä¼°ï¼ˆç”¨äº BERTScoreï¼‰", height=100)

if query:
    with st.spinner("ğŸ§  æ­£åœ¨åˆ†æå¹¶ç”Ÿæˆå›ç­”..."):
        start_time = time.time()

        # 1. æ£€ç´¢ & rerank
        retrieved_docs = retriever.get_relevant_documents(query)
        reranked_docs = rerank(query, retrieved_docs, top_k=3)

        # 2. æ„é€  Prompt å¹¶æ¨ç†
        context = "\n\n".join([doc.page_content for doc in reranked_docs])
        prompt = prompt_template.format(context=context, question=query)

        st.markdown("### ğŸ“Œ å›ç­”ï¼š")
        output_placeholder = st.empty()
        full_response = ""

        for chunk in llm.stream(prompt):
            full_response += chunk.content
            output_placeholder.markdown(full_response)

        # 3. æ—¶é—´ç»Ÿè®¡
        end_time = time.time()
        elapsed_time = round(end_time - start_time, 2)
        st.success(f"âœ… æ¨ç†å®Œæˆï¼Œè€—æ—¶ {elapsed_time} ç§’ | ä½¿ç”¨æ¨¡å‹ï¼š`{selected_model}`")

        # 4. æ˜¾ç¤ºä¸Šä¸‹æ–‡æ–‡æ¡£
        with st.expander("ğŸ“š æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£ï¼ˆRerankedï¼‰"):
            for i, doc in enumerate(reranked_docs):
                st.markdown(f"#### æ–‡æ¡£ {i+1}")
                st.code(doc.page_content[:1000], language='markdown')

        # 6. BERTScoreï¼ˆéœ€è¦ç”¨æˆ·è¾“å…¥å‚è€ƒç­”æ¡ˆï¼‰
        if reference_answer.strip():
            st.markdown("### ğŸ” BERTScore è¯„ä¼°")
            P, R, F1 = bert_score([full_response], [reference_answer], lang="zh", verbose=False)
            st.write(f"**Precision:** {P[0]:.4f}")
            st.write(f"**Recall:** {R[0]:.4f}")
            st.write(f"**F1:** {F1[0]:.4f}")
